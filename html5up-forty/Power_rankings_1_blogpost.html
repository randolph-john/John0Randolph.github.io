<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>John G Randolph</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<link rel="icon" type="image/jpg" href="../images/logo3.png"/>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<a href="../index.html" class="logo">John <span>G <strong>Randolph</strong></span> .com</a>
						<nav>
							<a href="../blog_home.html">Blog home</a>
						</nav>
					</header>

				<!-- Banner -->
					<section id="banner" class="major">
						<div class="inner">
							<img style="float:right" width="300em" src="../images/power_rankings_blog_post/UWPowerRankingsLogo.png" alt="ultiworld graphic">
								<h1 style="font-size:2.5em">Ultiworld <strong> Power Rankings </strong><br />
								<span style="font-size:.585em">How predictive are they?</span></h1>
								<ul class="actions">
									<li><a href="#main" id="enter-tax" class="button large next scrolly" onclick='onStart();'>Read</a></li>
								</ul>
						</div>

					</section>

				<!-- this will be filled in by inject-html.js -->
					<section id="main" class="major">
						<div class="inner">
						<h2>Intro</h2>
						<p>
							I've never been quite sure how to interpret the Ultiworld power rankings. I, like all ultimate players, care only
							about my team's finish at nationals. Therefore I usually view Ultiworld power rankings as an imprecise yardstick
							by which to measure my team's chances at nationals. I am always happy to see my team rise in the rankings and
							disappointed to see it fall. But how precise is the yardstick? If my team is ranked near the bottom or not at all,
							how much should we fret (how destined are we to lose?); if my team is ranked near the top, how much should we rejoice
							(how assured are we of success?)?
						</p>
						<p>
							To some degree, the rankings are accurate. If my team rises to #1 on the rankings, surely we are in a good spot to
							finish well at nationals; if my team falls from the rankings entirely, we will probably struggle at nationals, if
							we get there at all.
						</p>
						<p>
							The time of year matters too: at the beginning of the season, the predictions are probably less accurate. The data
							provided by tournaments should increase the precision of rankings as nationals approaches.
						</p>
						<p>
							I also wonder about rankings between divisions. Are Men's or Women's more accurate (or the same)? D1 or D3? College or club?
						</p>
						<h2>The approach</h2>
						<p>
							I'll explore these questions in a series of articles (hopefully). We'll start with one basic case, and probably
							the best one: the Men's and Women's D1 college divisions. Using these divisions has a few advantages:
						</p>
						<ul>
							<li>
								They have a long season. Over the season a steadily increasing amount of data is gathered about the teams
								through tournaments. The club season, in comparison, is shorter and has more sporadic tournament play
							</li>
							<li>
								Rosters are steady over the course of the season. In club, many rosters are smaller at early season tournaments,
								meaning the data gathered is less useful
							</li>
							<li id="footnote-1-reference">
								It is harder to predict solely from rosters in college than in club, meaning that the tournament data makes up
								a larger portion of the prediction <a href="#footnote-1">[1]</a>
							</li>
							<li>
								A larger number of Ultiworld contributors contribute to the D1 rankings than the D3 rankings, meaning they are
								a more stable average of people's opinions
							</li>
						</ul>
						<p>
							We will use as our gold standard labels the placement of each team at nationals. This data is noisy as there's a
							lot of variance within a single tournament, but it is unbiased and we have plenty of data points between 16 teams
							x 8 seasons x 2 divisions. Nationals is all that anyone cares about, so it makes sense as our gold standard.
						</p>
						<p>
							There are a few drawbacks with this approach. They are presented in <span style="font-weight:bold;">bold</span> alongside how we will choose to address them.
						</p>
						<ul>
							<li>
								<span style="font-weight:bold;">Due to the bid system, there are teams at nationals outside of the top 20. </span>
								We will ignore the bottom 4 finishing teams at nationals
							</li>
							<li>
								<span style="font-weight:bold;">Ultiworld's power rankings are not meant to be predictive of nationals finish. </span>
								Maybe. Ultiworld doesn't say on their site exactly what the power rankings are meant to convey, but it's likely
								that they are supposed to be predictions about the current strength of each team, ie if nationals was played on
								the day of the prediction. But even if they're not meant to be predictive we can still evaluate how predictive they are.
							</li>
							<li>
								<span style="font-weight:bold;">What metric do we use to evaluate the accuracy of predictions?</span>
								<a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman's ranking correlation coefficient (Spearman's rho)</a>
								is a widely-used measure of accuracy of ordinal rankings. In our setting, it only differs from
								<a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a>by a constant factor, so we'll use MSE,
								as it is easier to interpret.
							</li>
							<li>
								<span style="font-weight:bold;">What about ties?</span>
								We'll account for ties by setting the number to be the team's “correct” rank given the tie. For example, the
								four teams eliminated in quarterfinals who tie for 5th are each given a rank of 6.5 (halfway between 5th and
								8th). Predictions of 5 and 8 are equally accurate for teams eliminated in quarters, as are predictions of 1 and 12.
							</li>
							<li>
								<span style="font-weight:bold;">What about teams in Ultiworld's top 16 that don't qualify for nationals?</span>
								We'll give them a ranking of 21. There's an argument to be had that this should be a bigger penalty, but oh well.
							</li>
							<li>
								<span style="font-weight:bold;">What about the 2020 and 2021 college seasons?</span>
								In 2020 nationals was cancelled. The 2021 series was a short season whose champions were largely determined by
								which teams were able to practice together and with other anomalies (essentially no regular season tournaments;
								uncertainty about school eligibility). We'll exclude both the 2020 and 2021 seasons.
							</li>
							<li>
								<span style="font-weight:bold;">What about BYU?</span>
								As BYU forfeits the series, we will remove them from the Ultiworld rankings.
							</li>
						</ul>
						<h2>Results</h2>
						<p>
							These assumptions allow us to look at the accuracy over time of predictions in Ultiworld's power rankings for Men's and
							women's college teams from 2014 to 2023. We can scrape Ultiworld and run the numbers to generate the following graph. The
							graph is below, with men's in red and women's in blue.
						</p>
						<figure>
							<img style="text-align:center" width="1000em" src="../images/power_rankings_blog_post/Top16WithLegend.png" alt="Scatterplot of power rankings accuracy">
							<!-- <figcaption>Scatterplot of the accuracy of Ultiworld's power rankings as predictions of nationals finish.</figcaption> -->
						</figure>
						<p>
							There are a couple straightforward interesting takeaways:
						</p>
						<ul>
							<li>Predictions in the women's division are generally a bit more accurate than the men's division</li>
							<li>In both divisions, predictions do get more accurate as nationals gets closer</li>
						</ul>
						<p>
							That's about all I can see to take away from this graph.
						</p>
						<h2>Conclusion</h2>
						<p>
							There's a lot more to be done with this framework. A few ideas: how accurate is D1 vs D3; USAU rankings vs Ultiworld
							rankings; club vs college? How much stability is there in each different division, over the course of the season and
							over the course of multiple seasons? Does Ultiworld systematically over-rank or under-rank groups of teams such as
							blue-blood teams, teams new on the scene, or teams from specific regions? Is there a way we can use the USAU and Ultiworld
							rankings to come up with significantly more accurate predictions than either? Hopefully I'll follow up with blog posts
							exploring each those questions.
						</p>
						<h4>
							Links
						</h4>
						<ul>
							<li><a href="https://colab.research.google.com/drive/1Zc54Jwjrf_bxaw9paa_rdrFCdNEnJYXD?usp=sharing">Code</a></li>
							<li><a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman's rho</a></li>
							<li><a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean Squared Error</a></li>
						</ul>

						<p id="footnote-1"><a href="#footnote-1-reference">[1]</a> This an unproven belief of mine. It would be good to follow up and
							compare the accuracy of the first ranking of the season of club teams vs the same of college teams.
						</p>
					</div>
					</section>


				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="../assets/Randolph.Resume.pdf" download="Randolph.Resume.pdf" class="icon alt fa-file"><span class="label">Resume</span></a></li>
								<li><a href="https://github.com/randolph-john" class="icon alt fa-github"><span class="label" style="color:black;">GitHub</span></a></li>
								<li><a href="https://www.linkedin.com/in/randolph-john/" class="icon alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
								<li><a href="mailto:john_randolph@alumni.brown.edu" class="icon alt fa-envelope"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; John Randolph 2023</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="banzhof-inject-html.js"></script>
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	</body>
</html>
